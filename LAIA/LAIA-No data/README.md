# Beyond Memorization: Violating Privacy Via Inference With Large Language Models

# [25.01.24] Synthetic Examples
We release the synthetic examples that are part of our evaluation in [arxiv](https://arxiv.org/abs/2310.07298v1). For a more detailed explanation of the example creation, we refer to the paper appendix. Additionally, we want to make the following relevant disclaimers and notes about the examples:

- While each conversation is seeded with a complete synthetic profile, the evaluation per profile is only on one of the profile features (denoted by "feature").
- Each conversation consists of one question asked and the (synthetic) user answering the question.
- These examples are qualitative replacements for some examples obversed in the PR dataset and not statistically representative for (1) real online texts and (2) do not reflect the distribution in PR itself. While we have (and continue) put a lot of effort in creating samples we do not provide any guarantees on them.

# Repository Description 

This is the accompanying code repository to the paper "Beyond Memorization: Violating Privacy Via Inference With Large Language Models", preprint available on [arxiv](https://arxiv.org/abs/2310.07298v1). The code will be released once the manuscript is published. For any questions, please feel free to contact the authors.

------
**Authors**:<br>
Robin Staab, robin.staab@inf.ethz.ch<br>
Mark Vero, mark.vero@inf.ethz.ch<br>
Mislav BalunoviÄ‡, mislav.balunovic@inf.ethz.ch<br>
Martin Vechev, martin.vechev@inf.ethz.ch
